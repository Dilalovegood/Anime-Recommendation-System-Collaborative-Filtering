# -*- coding: utf-8 -*-
"""Anime Recommendation System - Collaborative Filtering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lnTeJ3dx02ZD3taLr0DZ6UdiLkGY7EHP

# 1. Data Understanding

## Import File
"""

import pandas as pd
import numpy as np
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

from google.colab import files

files.upload()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d 'CooperUnion/anime-recommendations-database'
!unzip anime-recommendations-database.zip

# load the dataset
anime = pd.read_csv('anime.csv')
ratings = pd.read_csv('rating.csv')

print('Jumlah anime : ', len(anime))
print('Jumlah rating : ', len(ratings))

"""# 2. Univariate Exploratory Data Analysis
Variabel-variabel pada dataset anime adalah sebagai berikut:

- anime_id – ID unik dari MyAnimeList.net yang mengidentifikasi sebuah anime.

- name – Nama lengkap dari anime.

- genre – Daftar genre anime yang dipisahkan dengan koma.

- type – Jenis anime, seperti movie, TV, OVA, dll.

- episodes – Jumlah episode dari anime tersebut (bernilai 1 jika merupakan film).

- rating – Rata-rata penilaian dari pengguna terhadap anime ini (dari skala 1 sampai 10).

- members – Jumlah anggota komunitas yang menjadi bagian dari "grup" anime ini.


Variabel-variabel pada dataset Rating :
- user_id – ID pengguna yang dihasilkan secara acak dan tidak dapat diidentifikasi.

- anime_id – ID anime yang telah diberi rating oleh pengguna ini.

- rating – Penilaian yang diberikan pengguna terhadap anime ini (bernilai -1 jika pengguna telah menonton anime tetapi tidak memberikan rating).

## Tujuan

Pada proyek ini, beberapa variabel akan di eksplorasi. Variabel anime_id akan digunakan untuk mapping, variabel rating digunakan untuk membentuk matriks user-item dan akan diolah oleh algoritma Collaborative Filtering untuk mencari kesamaan antar pengguna sedangkan variabel name akan digunakan untuk hasil output rekomendasi.

## Eksplorasi Variabel Animes
"""

anime.head()

anime.info()

print("Banyak data: ", len(anime["anime_id"]))
print("Nama anime yang tersedia: ", anime.name.unique())
print("Type anime yang tersedia: ", anime.type.unique())
print("Genre yang tersedia: ", anime.genre.unique())

#misisng values
print('Jumlah Genre : ', len(anime.genre.unique()))
print('Jumlah Type : ', len(anime.type.unique()))
print('Jumlah Rating : ', len(anime.rating.unique()))

"""**Hasil eksplorasi:**
- Ada 7 kolom dalam dataset anime
- Jumlah seluruh baris adalah 12.294
- Ada 4 variabel bertipe data object, 2 integer dan 1 float
- Ada missing value pada variabel genre, tipe dan rating

## Eksplorasi Variabel Ratings
"""

ratings.head()

ratings.info()

ratings.describe()

print('Jumlah user yang memberikan rating : ', len(ratings['user_id'].unique()))
print('Jumlah anime yang memiliki rating : ', len(ratings.anime_id.unique()))
print('Jumlah data rating: ', len(ratings["rating"].unique()))

"""# 3. Data Preprocessing

## Menggabungkan Anime
"""

import numpy as np

# Menggabungkan seluruh anime_id pada kategori Restaurant
anime_all = np.concatenate((
    anime.anime_id.unique(),
    ratings.anime_id.unique()
))

# Mengurutkan data dan menghapus data yang sama
anime_all = np.sort(np.unique(anime_all))

print('Jumlah seluruh data anime berdasarkan anime_id: ', len(anime_all))

all_anime = pd.merge(ratings, anime[['anime_id', 'name', 'genre']], on='anime_id', how='left')
all_anime

"""# 4. Data Preparation

**Anime**
"""

# Cek missing value dengan fungsi isnull()
anime.isnull().sum()

# Tangani missing value
anime['genre'] = anime['genre'].fillna('Unknown')
anime['type'] = anime['type'].fillna('Unknown')
anime = anime.dropna(subset=['rating'])  # Hapus rating NaN (optional)

# Cek ulang
print(anime.isnull().sum())

"""**Rating**"""

# Cek missing value dengan fungsi isnull()
ratings.isnull().sum()

# Hapus rating -1 (menonton tapi tidak memberikan rating)
ratings = ratings[ratings['rating'] >= 0]
ratings

"""**Encode user_id dan anime_id**

"""

# Ambil user_id dan anime_id unik, ubah ke list
user_ids = ratings['user_id'].unique().tolist()
anime_ids = ratings['anime_id'].unique().tolist()

# Buat dictionary: user_id → index
user_to_encoded = {x: i for i, x in enumerate(user_ids)}
encoded_to_user = {i: x for i, x in enumerate(user_ids)}

# Buat dictionary: anime_id → index
anime_to_encoded = {x: i for i, x in enumerate(anime_ids)}
encoded_to_anime = {i: x for i, x in enumerate(anime_ids)}

"""**Mapping hasil encoding ke DataFrame**"""

# Mapping ID asli ke index
ratings['user'] = ratings['user_id'].map(user_to_encoded)
ratings['anime'] = ratings['anime_id'].map(anime_to_encoded)

"""**Informasi dasar jumlah data**"""

num_users = len(user_to_encoded)
num_animes = len(anime_to_encoded)

min_rating = ratings['rating'].min()
max_rating = ratings['rating'].max()

print(f'Jumlah user: {num_users}, Jumlah anime: {num_animes}')
print(f'Rating minimum: {min_rating}, Rating maksimum: {max_rating}')

"""## Anime
Mengatasi Missing Value
"""

# Mengecek kembali missing value pada variabel all_anime_clean
all_anime.isnull().sum()

# Membersihkan missing value dengan fungsi dropna()
all_anime_clean = all_anime.dropna()
all_anime_clean

# Mengecek kembali missing value pada variabel all_anime_clean
all_anime_clean.isnull().sum()

# Mengurutkan buku berdasarkan anime_id kemudian memasukkannya ke dalam variabel fix_anime
fix_anime = all_anime_clean.sort_values('anime_id', ascending=True)
fix_anime

"""## Mengatasi Data Duplikat"""

# Membuang data duplikat pada variabel preparation
preparation = fix_anime.drop_duplicates('anime_id')
preparation

# Menghapus anime yang memiliki rating -1 dan 0
preparation = preparation[preparation['rating'] >= 1]
preparation

# Mengecek berapa jumlah fix_anime
len(fix_anime.anime_id.unique())

"""Konversi ke **list**"""

# Mengonversi data series 'anime_id' menjadi dalam bentuk list
id = preparation['anime_id'].tolist()

# Mengonversi data series ‘name’ menjadi dalam bentuk list
anime_name = preparation['name'].tolist()

# Mengonversi data series ‘genre’ menjadi dalam bentuk list
anime_genre = preparation['genre'].tolist()


print(len(id))
print(len(anime_name))
print(len(anime_genre))

# Membuat dictionary untuk data ‘d’, ‘anime_name’, ‘anime_genre’
anime_new = pd.DataFrame({
    'id': id,
    'anime_name': anime_name,
    'anime_genre': anime_genre
})
anime_new

"""## Membagi Data untuk Training dan Validasi"""

# Mengacak dataset
df = ratings.sample(frac=1, random_state=42)
df

# Normalisasi rating (0–1)
min_rating = df['rating'].min()
max_rating = df['rating'].max()

x = df[['user', 'anime']].values
y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

train_indices = int(0.8 * df.shape[0])
x_train, x_val = x[:train_indices], x[train_indices:]
y_train, y_val = y[:train_indices], y[train_indices:]

"""# 4. Model Development dengan Collaborative Filtering"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

class AnimeRecommender(tf.keras.Model):
    def __init__(self, num_users, num_anime, embedding_size=20):
        super(AnimeRecommender, self).__init__()
        self.user_embedding = layers.Embedding(num_users, embedding_size)
        self.user_bias = layers.Embedding(num_users, 1)
        self.anime_embedding = layers.Embedding(num_anime, embedding_size)
        self.anime_bias = layers.Embedding(num_anime, 1)

    def call(self, inputs):
        user_vector = self.user_embedding(inputs[:, 0])
        user_bias = self.user_bias(inputs[:, 0])
        anime_vector = self.anime_embedding(inputs[:, 1])
        anime_bias = self.anime_bias(inputs[:, 1])

        dot_user_anime = tf.reduce_sum(user_vector * anime_vector, axis=1, keepdims=True)
        return tf.nn.sigmoid(dot_user_anime + user_bias + anime_bias)

# Inisialisasi model
num_users = len(user_to_encoded)
num_anime = len(anime_to_encoded)

model = AnimeRecommender(num_users, num_anime)
model.compile(
    loss='binary_crossentropy',
    optimizer=keras.optimizers.Adam(0.0001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""**Train Model**"""

history = model.fit(
    x_train, y_train,
    validation_data=(x_val, y_val),
    epochs=5,
    batch_size=256
)

"""proses training model cukup smooth, kita memperoleh nilai error akhir sebesar sekitar 0.1318 dan error pada data validasi sebesar 0.1324. Nilai tersebut cukup bagus untuk sistem rekomendasi."""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""# 5. Prediksi Rekomendasi Anime untuk 1 User"""

import numpy as np

anime_df = anime_new        # dataframe berisi info anime
df = pd.read_csv('rating.csv')
ratings = ratings

# Ambil 1 sample user
user_id = ratings['user_id'].sample(1).iloc[0]

# Ambil anime yang sudah ditonton user
anime_watch_by_user = ratings[ratings['user_id'] == user_id]

# Ambil anime yang belum ditonton user
anime_not_watch = anime_df[~anime_df['id'].isin(anime_watch_by_user['anime_id'])]['id']

# Intersect dengan anime yang ada di dictionary encoded
anime_not_watch = list(set(anime_not_watch).intersection(set(anime_to_encoded.keys())))

# Ubah jadi format input untuk prediksi (user_id, anime_id)
anime_not_watch_encoded = [[anime_to_encoded[x]] for x in anime_not_watch]
user_encoded = user_to_encoded[user_id]
user_anime_array = np.hstack((np.full((len(anime_not_watch_encoded), 1), user_encoded), anime_not_watch_encoded))

# Prediksi rating untuk anime yang belum ditonton user
predicted_ratings = model.predict(user_anime_array).flatten()

# Ambil indeks dari top 10 rating tertinggi
top_ratings_indices = predicted_ratings.argsort()[-10:][::-1]

# Ambil anime_id asli dari hasil rekomendasi
# Corrected: Access the original anime ID directly from the anime_not_watch list
recommended_anime_ids = [
    anime_not_watch[i] for i in top_ratings_indices
]

print('Menampilkan rekomendasi untuk user:', user_id)
print('=' * 30)

print('\nAnime dengan rating tertinggi dari user:')
print('-' * 30)

# 5 anime dengan rating tertinggi dari user tersebut
top_anime_user = (
    anime_watch_by_user.sort_values(by='rating', ascending=False)
    .head(5)
    .anime_id.values
)

top_anime_rows = anime_df[anime_df['id'].isin(top_anime_user)]
for row in top_anime_rows.itertuples():
    print(f"{row.anime_name} | Genre: {row.anime_genre}")

print('-' * 30)
print('Top 10 Rekomendasi Anime:')
print('-' * 30)

# Ambil informasi anime dari hasil rekomendasi
recommended_anime = anime_df[anime_df['id'].isin(recommended_anime_ids)]
for row in recommended_anime.itertuples():
    print(f"{row.anime_name} | Genre: {row.anime_genre}")